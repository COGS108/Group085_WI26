{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Anusha Malla: Project administration, Software, Writing - review & editing\n",
    "- Fatimah Alhumrani:  Conceptualization, Analysis, Software, Visualization\n",
    "- Hanwen Chen: Project administration, Software, Background research, Writing - review & editing\n",
    "- Nawaf Ahmed: Conceptualization, Data curation, Methodology, Writing - original draft\n",
    "- Tom Klappenecker: Conceptualization, Analysis, Data curation, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is food desert status associated with differential access to McDonald’s versus Chipotle restaurants across U.S. census tracts? Specifically, do food desert census tracts have a shorter average distance to McDonald’s locations and a lower likelihood of containing a Chipotle location compared to non-food desert tracts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Food deserts refer to areas where residents' access to affordable, healthy food options is restricted or nonexistent due to the absence of grocery stores within convenient traveling distance. According to Food Empowerment Project's description, people’s choices about what to eat are severely limited by the options available to them and what they can afford, and many food deserts contain an overabundance of fast food chains selling cheap “meat” and dairy-based foods that are high in fat, sugar and salt.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1)\n",
    "\n",
    "Previous studies have identified socio-economic factors that correlates with the presence of food desert. In *Characteristics and Influential Factors of Food Deserts*<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2), the authors find that areas with higher level of poverty are more likely to become food deserts, regardless of urban or rural designation of that area. For other factors, such as vehicle availability and use of public transportations, the association with food desert status varies across very dense urban areas, less dense urban areas, and rural areas. This study has shown that in less urban and rural areas, the percentage of racial minority population affects the food desert status of an area, where food deserts tracts have a greater concentration of minorities. The study has also shown differences across geographical locations within the United States, where low-income populations in some regions are less vulnerable to access problems than low income populations in other regions. However, problems exist in this study. One such problem is that during the regression analysis, the study only examines the food deserts status of the census tracts that are classified as low income. While low-income and food access jointly define food desert status, analyzing the two properties concurrently can distort the relationship between poverty-related variables, such as unemployment rate and poverty rate, and food desert status.\n",
    "\n",
    "An article published by Addy Yater aimed to examine the difference in grocery accessibility between food deserts and non-food deserts in Indianapolis, Indiana<a name=\"cite_ref-3\"></a><sup>3</sup>. In the article, Yater found that poorer areas contained no grocery stores, while wealthier areas had plenty. A limitation of Yater's study, however, is that it focuses exclusively on regions within Indianapolis, Indiana, which may not be representative of the entire United States. Another problem is that, like the previous study, Yater associates low-income areas with food deserts, which can confound the measurement of other variables within the region. In our study, we aim to compare the accessibility of healthy versus unhealthy foods directly in each region, regardless of whether it is classified as a food desert. While McDonald’s is generally regarded as unhealthy, Chipotle is often considered a healthier alternative within the fast-food industry. Therefore, we chose McDonald’s and Chipotle as the unhealthy and healthy food options, respectively, to compare their accessibility in both food desert and non-food desert areas.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> Food Empowerment Project. *Food Deserts*. FoodIsPower.org. 2026. https://foodispower.org/access-health/food-deserts/\n",
    "2. <a name=\"cite_note-2\"></a> Dutko, P., Ver Ploeg, M., & Farrigan, T. (2012) *Characteristics and Influential Factors of Food Deserts*, Economic Research Service, U.S. Department of Agriculture, ERR-140. https://www.ers.usda.gov/publications/pub-details?pubid=45017\n",
    "3.  <a name=\"cite_note-3\"></a>Yater, A. *Correlation Between Food Deserts and Fast-food Restaurants*. https://storymaps.arcgis.com/stories/c85cf89d1516498d9645c325b3f5d814"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that McDonald’s locations will be more densely concentrated in or near food desert census tracts compared to Chipotle locations. Specifically, we predict a positive association between food desert status and proximity to McDonald’s, and a weaker or negative association between food desert status and proximity to Chipotle.\n",
    "\n",
    "This prediction is based on prior research showing that lower-income and minority communities (areas more likely to be classified as food deserts) tend to have a higher density of traditional fast-food restaurants. In contrast, fast-casual restaurants such as Chipotle are more commonly located in higher-income areas. Therefore, we expect McDonald’s to be more accessible in food desert regions than Chipotle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "1. The ideal dataset I would want to answer this question would have the variables zip code, food desert status (is a food desert or is not a food desert), poverty rate, has_McDonald's (whether the area has a McDonald's), and has_Chipotle (whether the area has a Chipotle). We would need to have 7000 observations. These data would be collected using datasets of the McDonald's and Chipotle locations and the US census data covering whether certain areas are food deserts or not. These data would be stored in a .csv or .xlsx file, so I would be organized in a semi-structured way.\n",
    "   \n",
    "2. The datasets are below:\n",
    "   1. Dataset 1 (link https://www.ers.usda.gov/data-products/food-access-research-atlas) - A table that contains the official US census data as of 2010 for food deserts. This dataset uses census tract for the location scaling, and has the poverty rate and population of each census tract. This dataset is publicly available.\n",
    "   2. Dataset 2 (link https://www.kaggle.com/datasets/jacopomazzoni/mcdonalds-locations-2025/data) - A table containing all of the McDonald's locations as of 2025. We will use the zip code column to match McDonald's locations to food desert locations. This dataset is publicly available.\n",
    "   3. Dataset 3 (link https://www.kaggle.com/datasets/jeffreybraun/chipotle-locations) - A table containing all of the Chipotle locations as of 2020. We will use the address column to match Chipotle locations to food desert locations. This dataset is publicly available.\n",
    "\n",
    "\n",
    "Updated portion to address Project Proposal Feedback:\n",
    "\n",
    "3. Although the McDonalds dataset (2025) and Chipotle dataset (2020) are more recent than the 2010 Census, we mitigatee the temporal mismatch by geocoding all store addresses to 2010 Census tract boundaries. While some new locations were added after 2010, most store locations have remained stable over time, and the number of post-2010 additions is small relative to the pre-2010 total. Therefore, our analysis using 2010 tracts provides a reasonable approximation of store presence relative to the 2010 population and food desert metrics.\n",
    "\n",
    "How We Plan to Combine the Datasets\n",
    "\n",
    "We can see that the datasets are not on the same temporal scale (food desert data is from 2010, Chipotle from 2020, and McDonald’s from 2025), we plan to geocode all store addresses using the 2010 Census boundaries. Specifically each Chipotle and McDonald’s address will be standardized and processed through the U.S. Census Geolocator API using the 2010 Census benchmark and vintage. This process maps each store to the census tract as it existed in 2010, ensuring that we can link modern store locations back to historical food desert data.\n",
    "\n",
    "By combining the datasets in this way, we can count the number of Chipotle and McDonald’s stores per 2010 census tract, flag tracts that contain at least one store or calculate the number of stores in each tract, compare store presence with food desert indicators, such as low-income tracts or areas with limited access to grocery stores, and identify correlations between fast food prevalence and food access challenges, even though store data is from a later time period.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.67.3)\n",
      "Requirement already satisfied: gdown in /usr/local/python/3.12.1/lib/python3.12/site-packages (5.2.1)\n",
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (from gdown) (4.14.2)\n",
      "Requirement already satisfied: filelock in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gdown) (3.24.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'get_data' has no attribute 'get_gdrive'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# replace the urls and filenames in this list with your actual datafiles\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# yes you can use Google drive share links or whatever\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# format is a list of dictionaries; \u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# each dict has keys of \u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m#   'url' where the resource is located\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#   'filename' for the local filename where it will be stored \u001b[39;00m\n\u001b[32m     22\u001b[39m datafiles = [\n\u001b[32m     23\u001b[39m     { \u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhttps://drive.google.com/uc?id=1oMl4m9py5hXGuqA-PodOLejLrxdv9CHx\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mus_census_food_desert_data_2010.csv\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     24\u001b[39m     { \u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhttps://drive.google.com/uc?id=1pAxxvfxl8hRdFJ-3GGnf0lmAeA18t9nJ\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mus_census_food_desert_var_lookup.csv\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     25\u001b[39m     { \u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhttps://drive.google.com/uc?id=1Z8FcNKAD1GJz91MBwXPYr6GN0Mh9obZ5\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mmcdonalds_locations_2025.csv\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     26\u001b[39m     { \u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mhttps://drive.google.com/uc?id=1mj2jzE54MBWVcSxQmlgZdPAerJBPfeY1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mchipotle_locations_2020.csv\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m     27\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_gdrive\u001b[49m(datafiles,destination_directory=\u001b[33m'\u001b[39m\u001b[33mdata/00-raw/\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'get_data' has no attribute 'get_gdrive'"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "%pip install requests tqdm gdown pandas\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import glob\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "import find_tract # this is where we find the 2010 census tract for an address\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://drive.google.com/uc?id=1oMl4m9py5hXGuqA-PodOLejLrxdv9CHx', 'filename':'us_census_food_desert_data_2010.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1pAxxvfxl8hRdFJ-3GGnf0lmAeA18t9nJ', 'filename':'us_census_food_desert_var_lookup.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1Z8FcNKAD1GJz91MBwXPYr6GN0Mh9obZ5', 'filename':'mcdonalds_locations_2025.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1mj2jzE54MBWVcSxQmlgZdPAerJBPfeY1', 'filename':'chipotle_locations_2020.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_gdrive(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### McDonald's locations in the US (2025)\n",
    "\n",
    "1. Important Metrics for the McDonald’s Dataset:\n",
    "    1. City (city) – Originally called location, this column indicates the city in which the McDonald’s restaurant is located. This is a text field representing the city name within the United States. It allows for geographic grouping and can be used to map stores to Census tracts, ZIP codes, or metropolitan areas for further spatial analysis.\n",
    "\t2.\tStreet Address (address) – This column contains the full street address of the McDonald’s location, including street number, street name, and sometimes suite or unit numbers. The street address is essential for geocoding the store into latitude/longitude coordinates or mapping it to a Census tract. For example, “346 W Magnolia Ave” identifies a unique physical location where the store operates.\n",
    "\t3.\tState (state) – This indicates the U.S. state in which the McDonald’s store is located. It is a standard two-letter state abbreviation or full state name. This metric is useful for aggregating stores at the state level, comparing store density, or linking with demographic and socioeconomic data at the state level.\n",
    "\t4.\tCleaned Address (clean_address) – After preprocessing, we created a clean_address column, which contains the standardized version of the street address, suitable for batch geocoding. This ensures that the addresses can be accurately mapped to Census tracts using the Census Geolocator API.\n",
    "\t5.\tZIP code (zip) – Extracted from the cleaned address, this 5-digit ZIP code allows for linking stores to ZIP-level statistics and performing location-based analyses, such as identifying stores within food deserts or other socioeconomic contexts.\n",
    "\t6.\tUnique ID (id) – A simple integer identifier assigned to each row to uniquely distinguish each McDonald’s location. This is primarily for tracking and batch processing purposes and does not have geographic meaning.\n",
    "\n",
    "    These metrics together allow for a comprehensive geographic mapping of McDonald’s stores across the U.S., enabling analyses at the tract, ZIP, city, and state levels.\n",
    "\n",
    "2. Dataset Quality and Concerns\n",
    "\t1. After inspecting the dataset, we have not found major concerns.\n",
    "\t2. Missing data is minimal, and all rows have valid city, state, and address entries.\n",
    "\t3. Some minor issues, such as formatting inconsistencies in city names (e.g., “Washington DC” vs “Washington, DC”), have been corrected during preprocessing.\n",
    "\t4. Outliers or suspicious entries (e.g., missing ZIP codes or incomplete addresses) have been flagged and cleaned.\n",
    "\t5. Overall, the dataset is clean, tidy, and ready for geocoding, making it reliable for mapping McDonald’s stores to Census tracts or analyzing their distribution relative to population, income, and food access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "%reload_ext autoreload\n",
    "mcdonalds_dataset = pd.read_csv(\"data/00-raw/mcdonalds_locations_2025.csv\")\n",
    "\n",
    "# fixing incorrect location names\n",
    "mcdonalds_dataset[\"location\"] = mcdonalds_dataset[\"location\"].replace(\"Washington DC\", \"Washington, DC\")\n",
    "\n",
    "# creating clean addresses for the census geocoder api\n",
    "mcdonalds_dataset[\"clean_address\"] = mcdonalds_dataset.apply(\n",
    "    lambda row: find_tract.clean_address_mcdonalds(row[\"address\"], row[\"location\"]), axis=1\n",
    ")\n",
    "\n",
    "# modifying columns to structure them for batch geocoding\n",
    "mcdonalds_dataset.rename(columns={'location': 'city'}, inplace=True)\n",
    "mcdonalds_dataset[\"street\"] = mcdonalds_dataset[\"clean_address\"].apply(lambda x: x.split(\",\")[0])\n",
    "mcdonalds_dataset[\"zip\"] = mcdonalds_dataset[\"clean_address\"].apply(lambda x: x.split(\",\")[-1].split()[-1])\n",
    "mcdonalds_dataset[\"id\"] = range(1, len(mcdonalds_dataset) + 1)\n",
    "\n",
    "# creating an intermediate file for batch geocoding with the census geocoder api\n",
    "num_mcdonalds_outputs = (len(mcdonalds_dataset) // 10000) + 1\n",
    "for i in range(num_mcdonalds_outputs):\n",
    "    mcdonalds_dataset[[\"id\", \"street\", \"city\", \"state\", \"zip\"]].iloc[10000*i:10000*(i+1) - 1].to_csv(f\"data/01-interim/mcdonalds_batch_{i}.csv\", index=False)\n",
    "    find_tract.find_tract_batch(f\"data/01-interim/mcdonalds_batch_{i}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finding rows that have mismatches between locations and addresses\n",
    "# bad_rows = mcdonalds_dataset[\n",
    "#     ~mcdonalds_dataset.apply(\n",
    "#         lambda row: isinstance(row[\"address\"], str)\n",
    "#         and isinstance(row[\"location\"], str)\n",
    "#         and (\" \" + row[\"location\"] in row[\"address\"]),\n",
    "#         axis=1\n",
    "#     )\n",
    "# ]\n",
    "# print(bad_rows[[\"address\", \"location\"]].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chipotle Locations in the United States (2020)\n",
    "\n",
    "The Chipotle dataset contains information about all known Chipotle restaurant locations in the United States as of 2020. Each row represents a single store and provides its geographic and address information. The dataset is primarily structured to support spatial analysis, particularly for mapping store locations to census tracts and examining relationships with socioeconomic variables, such as food deserts or population density.\n",
    "\n",
    "1. Important Metrics:\n",
    "\t1.\tState – The two-letter abbreviation for the U.S. state in which the store is located (e.g., CA for California). This allows for grouping or filtering by state for regional analyses.\n",
    "\t2.\tLocation (City) – The city where the Chipotle store is located. This is useful for aggregation at the city level or mapping to municipal boundaries.\n",
    "\t3.\tAddress – The full street address of the store. This can be used to geocode the exact latitude and longitude of the store.\n",
    "\t4.\tLatitude and Longitude – Geospatial coordinates in decimal degrees. Latitude ranges from approximately 25°N (Florida) to 49°N (northern U.S.), and longitude ranges from approximately -125°W (west coast) to -67°W (east coast). These coordinates allow for precise spatial mapping and joining with census tract polygons or other geospatial datasets.\n",
    "\n",
    "    The dataset is mostly numeric in the latitude and longitude columns, while the state, city, and address columns are categorical or textual. It is already in a tidy format, with one observation per row and one variable per column.\n",
    "\n",
    "2. Potential Concerns:\n",
    "\t1. Overall, this dataset appears clean and well-structured, and we have not identified any major issues.\n",
    "\t2. There may be minor inconsistencies in city or address formatting (e.g., abbreviations, punctuation, or spelling variations) that could affect merging with other datasets or mapping to geographic boundaries.\n",
    "\t3. Duplicate entries are unlikely but should be checked, particularly for addresses that appear multiple times with slightly different formatting.\n",
    "\t4. Latitude and longitude values are expected to be numeric and within the continental U.S., but occasional outliers or errors could exist, especially for stores in territories or near borders. These should be flagged and verified.\n",
    "\t5. While missing values appear minimal, it is still important to confirm whether any fields (e.g., latitude, longitude, or address) are missing, as these would impact spatial joins and mapping analyses.\n",
    "\t6. Geocoding inaccuracies could arise if addresses have changed or were recorded inconsistently, which might lead to slightly mislocated coordinates when mapping to census tracts.\n",
    "\t7. Finally, any updates after 2020 (store openings or closings) are not reflected in this dataset, which could slightly bias analyses that rely on the most current distribution of stores.\n",
    "\n",
    "3. Next Steps for Data Cleaning and Exploration:\n",
    "\t1.\tLoad the dataset using pandas.\n",
    "\t2.\tVerify its tidy structure and column consistency.\n",
    "\t3.\tCheck the size of the dataset (number of rows and columns).\n",
    "\t4.\tExplore missing values and determine if they are missing at random or systematic.\n",
    "\t5.\tFlag any suspicious entries, such as stores with invalid coordinates (outside continental U.S.) or duplicated addresses.\n",
    "\t6.\tDecide how to handle missing or suspicious entries, either by filling, correcting, or dropping them, justifying the choice based on the analysis requirements.\n",
    "\t7.\tOptionally, write cleaned intermediate data to data/01-interim and fully processed data to data/02-processed.\n",
    "\t8.\tCompute summary statistics for key variables, such as the number of stores per state, number of stores per city, and distribution of latitude/longitude for mapping.\n",
    "\n",
    "This dataset provides a strong foundation for spatial analysis, particularly for investigating the relationship between Chipotle store locations and food access patterns in the U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "%reload_ext autoreload\n",
    "chipotle_dataset = pd.read_csv(\"data/00-raw/chipotle_locations_2020.csv\")\n",
    "\n",
    "# setting up columns for batch geocoding\n",
    "chipotle_dataset[\"id\"] = range(1, len(chipotle_dataset) + 1)\n",
    "chipotle_dataset.rename(columns={'address': 'street', 'zipcode': 'zip'}, inplace=True)\n",
    "\n",
    "num_chipotle_outputs = (len(chipotle_dataset) // 10000) + 1\n",
    "# creating an intermediate file for batch geocoding\n",
    "for i in range(num_chipotle_outputs):\n",
    "    chipotle_dataset[[\"id\", \"street\", \"city\", \"state\", \"zip\"]].iloc[10000*i:10000*(i+1) - 1].to_csv(f\"data/01-interim/chipotle_batch_{i}.csv\", index=False)\n",
    "    find_tract.find_tract_batch(f\"data/01-interim/chipotle_batch_{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2010 Census Food Desert Data\n",
    "\n",
    "This dataset contains information on U.S. census tracts from the 2010 Census, focusing on food access, income, population, and demographics. Each row is a census tract (roughly 4,000 residents on average). It is designed to identify food deserts, areas with limited access to affordable and nutritious food.\n",
    "\n",
    "We also merged in McDonald’s and Chipotle location data, counting how many of each restaurant are in each tract. This lets us compare food access with fast food availability.\n",
    "\n",
    "1. Key Metrics:\n",
    "\t1. Population & Demographics: Pop2010 (total residents), TractWhite, TractBlack, TractAsian, TractHispanic (counts by race/ethnicity).\n",
    "\t2. Income & Poverty: MedianFamilyIncome (USD), PovertyRate (% of residents below poverty line), TractLOWI (low-income residents).\n",
    "\t3. Food Access: LILATracts_1And10, LILATracts_halfAnd10, etc. — measure low-income residents with limited grocery access.\n",
    "\t4. Households: HUNVFlag (households without vehicles), LASNAP (residents receiving SNAP benefits).\n",
    "\t5. Restaurant Counts: num_mcdonalds and num_chipotle — number of locations per tract. Missing values are set to 0.\n",
    "\n",
    "2. Potential Concerns:\n",
    "\t1. We do not have any major concerns for this dataset because it is based on the official 2010 U.S. Census, which provides comprehensive coverage of all census tracts across the country. The tract-level population, demographic, and income data are standardized and collected using well-established methodologies. While some restaurant counts come from geocoding batches of McDonald’s and Chipotle locations, we filtered only the matched addresses and filled missing counts with 0, which minimizes potential errors. Overall, the data appear complete, consistent, and representative of U.S. census tracts, so there are no obvious systematic biases or major data quality issues that would affect tract-level analyses of food access.\n",
    "\n",
    "3. Data Cleaning & Wrangling:\n",
    "\t1. Loaded raw data and restaurant batches.\n",
    "\t2. Kept only matched addresses for McDonald’s and Chipotle.\n",
    "\t3. Created 11-digit GEOID codes for tracts.\n",
    "\t4. Merged restaurant counts into the main dataset.\n",
    "\t5. Filled missing restaurant counts with 0 and removed extra columns from merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "food_desert_dataset = pd.read_csv(\"data/00-raw/us_census_food_desert_data_2010.csv\", dtype=str)\n",
    "cols = [\n",
    "    \"id\",\n",
    "    \"input_address\",\n",
    "    \"match_status\",\n",
    "    \"match_type\",\n",
    "    \"matched_address\",\n",
    "    \"coordinates\",\n",
    "    \"tiger_line_id\",\n",
    "    \"side\",\n",
    "    \"statefp\",\n",
    "    \"countyfp\",\n",
    "    \"tract\",\n",
    "    \"block\"\n",
    "]\n",
    "mcdonalds_output = pd.concat(\n",
    "    (pd.read_csv(f, names=cols, dtype=str) for f in glob.glob(\"data/01-interim/mcdonalds_batch_*_output.csv\")),\n",
    "    ignore_index=True\n",
    ")\n",
    "chipotle_output = pd.concat(\n",
    "    (pd.read_csv(f, names=cols, dtype=str) for f in glob.glob(\"data/01-interim/chipotle_batch_*_output.csv\")),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# finding only matches with addresses that existed in the 2010 census\n",
    "mcdonalds_output = mcdonalds_output[mcdonalds_output[\"match_status\"] == \"Match\"]\n",
    "chipotle_output = chipotle_output[chipotle_output[\"match_status\"] == \"Match\"]\n",
    "\n",
    "# adding geoid columns to mcdonalds and chipotle outputs\n",
    "mcdonalds_output[\"GEOID\"] = mcdonalds_output[\"statefp\"].str.zfill(2) + mcdonalds_output[\"countyfp\"].str.zfill(3) + mcdonalds_output[\"tract\"].str.zfill(6)\n",
    "chipotle_output[\"GEOID\"] = chipotle_output[\"statefp\"].str.zfill(2) + chipotle_output[\"countyfp\"].str.zfill(3) + chipotle_output[\"tract\"].str.zfill(6)\n",
    "\n",
    "# finding counts of mcdonalds in each census tract\n",
    "mcd_counts = mcdonalds_output.groupby(\"GEOID\").size().reset_index(name=\"num_mcdonalds\")\n",
    "chip_counts = chipotle_output.groupby(\"GEOID\").size().reset_index(name=\"num_chipotle\")\n",
    "\n",
    "# ensure CensusTract is 11-digit string\n",
    "food_desert_dataset[\"CensusTract\"] = food_desert_dataset[\"CensusTract\"].astype(str).str.zfill(11)\n",
    "\n",
    "# merge counts (left join to keep all tracts)\n",
    "food_desert_dataset = food_desert_dataset.merge(mcd_counts, how=\"left\", left_on=\"CensusTract\", right_on=\"GEOID\")\n",
    "food_desert_dataset = food_desert_dataset.merge(chip_counts, how=\"left\", left_on=\"CensusTract\", right_on=\"GEOID\", suffixes=(\"_mcd\",\"_chip\"))\n",
    "\n",
    "# fill NaN counts with 0\n",
    "food_desert_dataset[\"num_mcdonalds\"] = food_desert_dataset[\"num_mcdonalds\"].fillna(0).astype(int)\n",
    "food_desert_dataset[\"num_chipotle\"] = food_desert_dataset[\"num_chipotle\"].fillna(0).astype(int)\n",
    "\n",
    "# drop extra GEOID columns if desired\n",
    "food_desert_dataset.drop(columns=[\"GEOID_mcd\",\"GEOID_chip\"], inplace=True)\n",
    "\n",
    "print(food_desert_dataset[\"num_mcdonalds\"].sum())\n",
    "print(food_desert_dataset[\"num_chipotle\"].sum())\n",
    "print(mcdonalds_output[\"statefp\"].head())\n",
    "print(mcdonalds_output[\"countyfp\"].head())\n",
    "print(mcdonalds_output[\"tract\"].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "Population data was obtained from the 2010 Census of the Population, where participation is a legal requirement rather than an opt-in process. Additionally, the datasets used are publicly released and intended for research and policy analysis, aligning with established ethical standards for secondary data use.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "According to the 2010 Census Coverage Measurement (CCM) Survey, two major sources of bias were identified. First, undercounting occurred among newborns, toddlers, and minority populations (primarily Black and Hispanic communities), often due to assumptions about household composition and residence in hard-to-count housing areas. Second, overcounting occurred in wealthier areas where individuals owned multiple properties, as well as among college students who were counted both at their family residence and their school address. While national population totals remain close to accurate, these issues can distort geographic and demographic representation at local levels, resulting in distributional bias.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "The population data used, including age, race, Hispanic ethnicity, and residence in group quarters, are derived from the 2010 Census of the Population and are aggregated into 0.5-kilometer-square grid cells. This spatial aggregation prevents identification of exact locations and individuals, thereby minimizing the risk of exposing personally identifiable information.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "This project recognizes that food deserts often overlap with low-income communities and communities of color. As a result, the analysis focuses on income, zoning, and business placement decisions, and findings are presented as geographic patterns rather than claims about individual behavior or health choices.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "The data used in this analysis is publicly available and aggregated at the census tract level, meaning it does not contain any personally identifiable information. As a result, risks related to individual data exposure are minimal. That said, it is still important to store datasets securely and limit access to project members to prevent misuse or misinterpretation of sensitive neighborhood-level indicators. Even aggregated data about food deserts and socioeconomic conditions can carry social implications if taken out of context, so maintaining basic data security and responsible handling practices helps ensure the analysis is used appropriately.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "Because this project relies exclusively on de-identified, aggregate-level public data, there is no mechanism through which individuals can be identified or request removal of personal information. However, this also means that individual communities may still be indirectly represented in ways that carry social meaning. Being mindful of how findings are framed is important to avoid reinforcing stereotypes or deficit-based narratives about low-income or minority neighborhoods.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "The datasets used for this project will only be retained for the duration of the analysis and reporting process and do not require long-term storage beyond the scope of the class project. Since the data is publicly available and non-sensitive, retention does not pose a privacy risk, but limiting prolonged storage helps reinforce responsible data practices and reduces the chance of future misuse or misinterpretation outside of the original research context.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "Wee recognize that this study lacks the direct engagement with affected communities. Our analysis may overlook qualitative factors such as transportation access, cultural food preferences, informal food networks, etc.. We acknowledge this limitation and avoid making prescriptive claims about community behavior without stakeholder input.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "We acknowledge that Census data and business location datasets may contain structural biases, including undercounting populations outside of mainland United States and uneven reporting of commercial activity. Therefore, we need to address this in our data analysis.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "Visualizations are constructed to reflect proportional differences accurately without exaggerating scale or selectively omitting data. We avoid misleading axis truncation and clearly label geographic boundaries and aggregation levels. Where uncertainty or limitations exist, they are explicitly stated in captions and discussion sections.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "All analysis relies on publicly available datasets without personally identifiable information. No individual-level data are displayed or inferred.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "All data cleaning, transformation, and visualization steps are documented in Jupyter notebooks. Code is version-controlled through GitHub, allowing the full workflow to be reproduced.\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "This project primarily conducts descriptive spatial analysis rather than predictive modeling. However, we recognize that variables such as zoning classification or income may act as proxies for race due to historical segregation patterns. We avoid using these variables to make normative judgments and interpret findings within broader structural contexts.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    "Because we are not building a predictive model that assigns outcomes to individuals, traditional fairness metrics are not applicable. However, we will examine results across demographic groups to ensure that patterns are not misrepresented or selectively highlighted in ways that reinforce stereotypes.\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "In this study, we will prioritize transparent, interpretable summary statistics rather than optimizing a performance metric.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    "Our study relies on descriptive statistics, which can be explained and replicated. We avoid using models without interpretation.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "We clearly state that correlation does not imply causation and that geographic overlap between food deserts and demographic variables does not reflect individual choices or capabilities. Limitations related to temporal mismatch, census undercounting, and omitted qualitative factors are explicitly acknowledged.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "This project is not deployed as a live decision-making system. However, if findings were to inform policy or planning, ongoing evaluation with updated datasets would be necessary to account for demographic and economic changes over time.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "As an academic analysis, the project does not directly affect individuals. However, if results were misinterpreted or shown to cause harm, revisions and clarifications would be issued to correct inaccuracies and prevent misleading conclusions.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "Since there is no automated system in production, rollback is not applicable. If analytical errors are identified, the repository can be updated or corrected via version control.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "We acknowledge that geographic analyses of food deserts could potentially be misused to stigmatize neighborhoods or justify inequitable investment decisions. To mitigate this risk, we frame findings in structural and policy contexts rather than attributing outcomes to individual or community deficiencies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Meet every Wednesday to discuss about the project*\n",
    "* *Complete the assigned individual tasks before each meet up*\n",
    "* *During meet up, discuss the viability of each section completed, propose changes if needed*\n",
    "* *Assign tasks during each meet up, tasks should be divided evenly*\n",
    "* *Keep group members up to date. Inform any difficulties in the groupchat*\n",
    "* *Help members if possible*\n",
    "* *Keep everyone noticed if a time does not work or anything unaccomplishable*\n",
    "* *In case where there is merge conflicts when trying to push from different branches. Inform other group members through the groupchat, once*\n",
    "  *consensus is reached, resolve any merge conflict accordingly*\n",
    "* *Always text the groupchat if merging to master branch*\n",
    "* *Do not make changes to any branches that you are not working with*\n",
    "* *Avoid targeting against others teammate, but do address your opinion in case there is a disagreement*\n",
    "* *Respect your teammate, spread positivity*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/11  |  7 PM | Clean the data, merge any necessary dataframes | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part | \n",
    "| 2/18 |  6 PM |  Finalize datasets, finish up any incompleted data cleaning & wrangling | Review/Edit wrangling/EDA; Discuss Analysis Plan | \n",
    "| 2/25  | 7 PM  | Import & Wrangle Data (Ant Man); EDA (Hulk)  | Discuss/edit Analysis; Complete project check-in  |\n",
    "| 3/4  | 7 PM  | Finish up EDA; Begin Analysis| Review/Edit wrangling/EDA; Discuss Analysis Plan  |\n",
    "| 3/11  | 7 PM  | Finish Analysis: Draft results/conclusion/discussion | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/18  | 7 PM  | Wrap Up, finish any incompleted work | Turn in Final Project & Group Project Surveys!!! |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
